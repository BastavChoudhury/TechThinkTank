
The ideal technique to dangle a toe in quantum physics according to experts, is thought to be through quantum computing. It strips away the complexities of the physical world and simplifies the fundamental ideas from quantum physics.

But why was quantum computing needed in the first place?

To answer that, we'll first have to examine what classical computing is and its limitations.
Quantum computing works mainly on the principle of ‘0’ and ‘1’, or ‘off’ and ‘on’. This merely illustrates the movement of electricity. When the system is in the "on" state, which is represented by state "1," electricity is seen to be flowing through the circuit; in the "off" state, which is represented by state "0," there is no electricity present in the circuit.

This flow of electricity in quantum computing is controlled by something called a ‘transistor’.   In essence, a transistor is a semiconductor device that helps regulate the flow of electricity by acting as a switch.

Now, millions of these transistors make up the integrated circuits that our incredibly complex computers are constructed from. Basically, everything we do with our machines may be seen as an electron disco.

Cool! But what is the limitation?

Since the 1960s, the power of our machines has continued to increase, making computers smaller while also becoming more powerful to the point where currently, computer components, notably transistors, are getting close to the size of an atom!

The number of transistors in a given area has doubled every less than two years since the 1970s, which means the size of transistors has kept on decreasing. This is called Moore’s law. 

For comparison, an atom's diameter is about 0.1 nanometres, whereas a transistor's diameter is about 7 nanometres.

Since the transistor has reached such a small size, comparable to that of an atom, the problem that occurs is that instead of bouncing off the barrier that stops the flow of electricity, the electron is able to flow through the barrier, thanks to a phenomenon called ‘tunnelling effect’.  

‘Quantum tunnelling’ is a quantum mechanical phenomenon where a particle can tunnel through a barrier that it could not otherwise pass through because it lacked the energy to do so. For instance, if a ball is thrown down a valley, it will have enough energy to roll up a hill, but because it abides by the law of conservation of energy, it will never rise above the height from whence it was thrown. This means that the ball cannot ever exist on the other side of the hill using the principles of classical physics. But, by the concept of quantum tunnelling, it can!

Every particle in quantum physics is a wave, and the amplitude of the wave at a given place determines the probability that the particle is there. Simply put, the probability of the particle existing at that point increases with increasing amplitude. This implies that the ball may also be present on the opposite side of the hill! This basically says that the ball doesn't cross the hill; it just pops up the other side. This is a case of quantum tunnelling.

Thus, we also conclude that a key distinction between classical and quantum computing is that the former relies on ‘deterministic states’ (i.e., 0 and 1) while the latter is founded on ‘probabilistic’ states.
